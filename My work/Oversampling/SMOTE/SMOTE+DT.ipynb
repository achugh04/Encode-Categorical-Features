{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d648028b",
   "metadata": {},
   "source": [
    "# Oversampling method approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# data = pd.read_csv(\"/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/pre-processing done/Pre-Processed-Encoded_Chugh_Baseline_Label_Encoding.csv\")\n",
    "# data = pd.read_csv('/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/pre-processing done/Pre-Processed_OneHotEncoding.csv')\n",
    "# data = pd.read_csv('/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/pre-processing done/Pre-Processed-Encoded_Chugh_LOOE_FOR_ALL.csv')\n",
    "data = pd.read_csv('/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/pre-processing done/Pre-Processed-Encoded_Chugh_WOE_FOR_ALL.csv')\n",
    "# data = pd.read_csv('/Users/abhiishekchugh/Documents/GitHub/CANN-for-Fraud-Detection/Automobile Insurance/data/pre-processing done/Pre-Processed-Encoded_Chugh.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7372f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting number of Fraud and non-Fraud\n",
    "pd.value_counts(data['FraudFound']).plot.bar()\n",
    "plt.title('Fraud class histogram')\n",
    "plt.xlabel('Fraud Found')\n",
    "plt.ylabel('Frequency')\n",
    "data['FraudFound'].value_counts()\n",
    "\n",
    "X = np.array(data.iloc[:, data.columns != 'FraudFound'])\n",
    "y = np.array(data.iloc[:, data.columns == 'FraudFound'])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53229f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Number policies X_train dataset: \", X_train.shape)\n",
    "print(\"Number policies  y_train dataset: \", y_train.shape)\n",
    "print(\"Number policies  X_test dataset: \", X_test.shape)\n",
    "print(\"Number policies  y_test dataset: \", y_test.shape)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "# data.columns.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae39522",
   "metadata": {},
   "source": [
    "## SMOTE Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d888ee",
   "metadata": {},
   "source": [
    "## Plotting the Oversampled data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e04ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train_res)\n",
    "\n",
    "# scatter plot of examples by class label\n",
    "for label, _ in counter.items():\n",
    "    row_ix = np.where(y_train_res == label)[0]\n",
    "    plt.scatter(X_train_res[row_ix, 0], X_train_res[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa905894-2070-46b8-b8e8-e9e9fb66865e",
   "metadata": {},
   "source": [
    "# Functions to create DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815513e-4032-49f6-98ef-493147bb8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Function to perform training with giniIndex.\n",
    "def train_using_gini(X_train, X_test, y_train):\n",
    "  \n",
    "    # Creating the classifier object\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
    "            random_state = 42,max_depth=5, min_samples_leaf=5)\n",
    "  \n",
    "    # Performing training\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    return clf_gini\n",
    "      \n",
    "# Function to perform training with entropy.\n",
    "def train_using_entropy(X_train, X_test, y_train):\n",
    "  \n",
    "    # Decision tree with entropy\n",
    "    clf_entropy = DecisionTreeClassifier(\n",
    "            criterion = \"entropy\", random_state = 42,\n",
    "            max_depth = 5, min_samples_leaf = 5)\n",
    "  \n",
    "    # Performing training\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    return clf_entropy\n",
    "\n",
    "# Function to make predictions\n",
    "def prediction(X_test, clf_object):\n",
    "  \n",
    "    # Predicton on test with giniIndex\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    #print(\"Predicted values:\")\n",
    "    #print(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "      \n",
    "    print(\"Confusion Matrix: \\n\",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "      \n",
    "    print (\"Accuracy : \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "      \n",
    "    print(\"Report : \",\n",
    "    classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75780c1-a6f8-4bdf-887c-6226b5ab00e2",
   "metadata": {},
   "source": [
    "# Training using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2d4ca-31b2-47b9-a0f9-52976acc4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_entropy = train_using_entropy(X_train_res, X_test, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1ab00-8d5d-4662-a150-edb74fdf154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_train = prediction(X_train_res,dt_entropy)\n",
    "cal_accuracy(y_train_res, y_pred_train)\n",
    "y_pred = prediction(X_test,dt_entropy)\n",
    "cal_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4924844-5c4a-4b63-92b3-1fd4541fb0d8",
   "metadata": {},
   "source": [
    "# Training using Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b7a6f-03f1-4d6a-8e30-cb2c999ef2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gini = train_using_gini(X_train_res, X_test, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c49c40-5f7a-4a99-91dc-89ea8cd27c75",
   "metadata": {
    "id": "lreKGwc3gLW-"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_train = prediction(X_train_res,dt_gini)\n",
    "cal_accuracy(y_train_res,y_pred_train)\n",
    "y_pred = prediction(X_test,dt_gini)\n",
    "cal_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff142ef7-f8b9-45da-bb0f-da2a4aa161e0",
   "metadata": {},
   "source": [
    "## Confusion matrix plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf8c3c-2cd4-467c-978a-96878b76bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7aea9-74ec-48b6-8db1-70fca1a6f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_tra = confusion_matrix(y_train_res, y_pred_train)\n",
    "\n",
    "print(\"Recall metric in the train dataset: {}%\".format(100*cnf_matrix_tra[1,1]/(cnf_matrix_tra[1,0]+cnf_matrix_tra[1,1])))\n",
    "print(\"Precision metric in the train dataset: {}%\".format(100*cnf_matrix_tra[0,0]/(cnf_matrix_tra[0,0]+cnf_matrix_tra[1,0])))\n",
    "\n",
    "\n",
    "\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_tra , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126ef7a-4297-47e8-a714-b61410003c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: {}%\".format(100*cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])))\n",
    "print(\"Precision metric in the testing dataset: {}%\".format(100*cnf_matrix[0,0]/(cnf_matrix[0,0]+cnf_matrix[1,0])))\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix , classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38c7e2-39d9-44a7-94c3-162a28eb454d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
